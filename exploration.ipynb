{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "=== DATASET OVERVIEW ===\n",
      "Shape: (1715, 202)\n",
      "Columns: ['V1', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102.1', 'V52.1', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200']\n",
      "=== DATA TYPES ===\n",
      "V1        int64\n",
      "V102    float64\n",
      "V103    float64\n",
      "V104    float64\n",
      "V105    float64\n",
      "         ...   \n",
      "V196    float64\n",
      "V197    float64\n",
      "V198    float64\n",
      "V199    float64\n",
      "V200    float64\n",
      "Length: 202, dtype: object\n",
      "=== FIRST 5 ROWS ===\n",
      "   V1      V102       V103        V104       V105       V106       V107  \\\n",
      "0   1  0.506699 -10.810651   74.792754  71.431942  34.704430  72.602519   \n",
      "1   1 -0.955542 -46.564180 -110.914030   9.615879  21.952367 -91.256936   \n",
      "2   7 -1.595105  -8.064150 -108.820483 -62.587168   4.926231  96.647456   \n",
      "3   4  0.608051 -51.248659   73.633311 -34.355499 -40.804242 -88.069314   \n",
      "4   2 -1.393286 -19.180590  101.630523  70.772108  -1.785993  38.035904   \n",
      "\n",
      "       V108      V109      V110  ...       V191      V192       V193  \\\n",
      "0  0.268082 -0.638445 -1.202652  ...  27.338075  0.786409  31.855907   \n",
      "1  1.254708  1.842626  0.335619  ... -64.602948 -2.040274  -9.951466   \n",
      "2  0.146147 -0.590777 -1.389004  ...  90.032817  1.427122   3.318559   \n",
      "3 -0.218186 -0.883454 -1.117455  ...  -5.804373 -0.036176   3.662683   \n",
      "4  0.818731  1.471921 -1.190006  ... -64.144511 -0.712612  36.003625   \n",
      "\n",
      "       V194        V195       V196       V197      V198        V199      V200  \n",
      "0 -1.574921  -89.310007 -61.501204  28.837418 -1.797913  -63.848927 -0.181080  \n",
      "1  0.280777  102.710491  49.791838 -32.920379  1.276826 -121.042869 -1.113853  \n",
      "2 -1.959151   48.858516  63.874527 -28.924198  1.321954   -1.899167  0.451294  \n",
      "3 -0.293838    5.640350 -58.901116 -69.051018  0.088887  -75.681789  1.113343  \n",
      "4  1.604523  -88.435002  28.485741  52.525530  0.859011  -15.121186  2.062864  \n",
      "\n",
      "[5 rows x 202 columns]\n",
      "=== BASIC STATISTICS ===\n",
      "                V1         V102         V103         V104         V105  \\\n",
      "count  1715.000000  1715.000000  1715.000000  1715.000000  1715.000000   \n",
      "mean      3.569096    -0.038326    -0.306232     1.935482    -0.927149   \n",
      "std       2.036791     1.138210    32.654635    70.986949    97.562285   \n",
      "min       1.000000    -3.994755   -57.513085  -124.784305  -168.858140   \n",
      "25%       2.000000    -0.816104   -28.345577   -59.592454   -84.017739   \n",
      "50%       3.000000    -0.025736    -0.643593     4.219022    -0.298099   \n",
      "75%       5.000000     0.733396    28.357541    61.751116    82.563057   \n",
      "max       7.000000     3.938847    57.608756   123.645341   168.278172   \n",
      "\n",
      "              V106         V107         V108         V109         V110  ...  \\\n",
      "count  1715.000000  1715.000000  1715.000000  1715.000000  1715.000000  ...   \n",
      "mean      0.190867     1.311055     0.016710    -0.023223    -0.018316  ...   \n",
      "std      29.242957   111.135900     1.164414     1.146641     1.120354  ...   \n",
      "min     -54.300323  -191.411311    -3.245967    -3.671699    -3.702545  ...   \n",
      "25%     -24.569904   -96.834531    -0.790202    -0.806626    -0.836345  ...   \n",
      "50%       0.484622     7.578079     0.060956    -0.022987    -0.017533  ...   \n",
      "75%      24.655946    97.025065     0.768353     0.781982     0.764843  ...   \n",
      "max      53.563675   193.007436     3.917322     3.499044     3.781478  ...   \n",
      "\n",
      "              V191         V192         V193         V194         V195  \\\n",
      "count  1715.000000  1715.000000  1715.000000  1715.000000  1715.000000   \n",
      "mean      1.877748    -0.006150     0.707688    -0.001346     1.356611   \n",
      "std      62.549806     1.141399    23.797261     1.163866    66.672756   \n",
      "min    -107.948978    -3.804873   -41.976427    -3.830143  -114.288125   \n",
      "25%     -51.875982    -0.794997   -20.448252    -0.789100   -57.099427   \n",
      "50%       2.451876    -0.048621     1.584555    -0.020664     3.273745   \n",
      "75%      56.996953     0.765060    21.550320     0.783541    59.852861   \n",
      "max     109.033866     4.452898    42.223188     3.194513   114.249236   \n",
      "\n",
      "              V196         V197         V198         V199         V200  \n",
      "count  1715.000000  1715.000000  1715.000000  1715.000000  1715.000000  \n",
      "mean      0.981589    -0.452664     0.040150     2.177157     0.038412  \n",
      "std      46.041394    41.706175     1.140162    70.774854     1.141834  \n",
      "min     -78.275844   -72.985073    -4.248330  -121.089170    -3.575126  \n",
      "25%     -39.576179   -36.503647    -0.735675   -59.756764    -0.715255  \n",
      "50%       0.888448    -0.825979     0.073496     1.799900     0.055020  \n",
      "75%      41.562628    35.799207     0.859035    64.442878     0.803337  \n",
      "max      79.689687    73.821609     3.235976   121.703768     3.779318  \n",
      "\n",
      "[8 rows x 202 columns]\n",
      "=== MISSING VALUES ===\n",
      "V1      0\n",
      "V102    0\n",
      "V103    0\n",
      "V104    0\n",
      "V105    0\n",
      "       ..\n",
      "V196    0\n",
      "V197    0\n",
      "V198    0\n",
      "V199    0\n",
      "V200    0\n",
      "Length: 202, dtype: int64\n",
      "=== UNIQUE VALUES IN CATEGORICAL COLUMNS ===\n",
      "V1: 7 unique values - [1 7 4 2 6 3 5]\n",
      "=== CLASS DISTRIBUTION (if applicable) ===\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('Cancer2025exam.csv')\n",
    "\n",
    "# Basic information about the dataset\n",
    "print(\"\\\n",
    "=== DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "print(\"\\\n",
    "=== DATA TYPES ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\\n",
    "=== FIRST 5 ROWS ===\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\\n",
    "=== BASIC STATISTICS ===\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\\n",
    "=== MISSING VALUES ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\\n",
    "=== UNIQUE VALUES IN CATEGORICAL COLUMNS ===\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' or df[col].nunique() < 20:\n",
    "        print(f\"{col}: {df[col].nunique()} unique values - {df[col].unique()[:10]}\")\n",
    "\n",
    "print(\"\\\n",
    "=== CLASS DISTRIBUTION (if applicable) ===\")\n",
    "# Check if there's a target variable\n",
    "possible_targets = ['diagnosis', 'Diagnosis', 'target', 'Target', 'class', 'Class', 'label', 'Label']\n",
    "for target in possible_targets:\n",
    "    if target in df.columns:\n",
    "        print(f\"\\\n",
    "{target} distribution:\")\n",
    "        print(df[target].value_counts())\n",
    "        print(f\"\\\n",
    "Percentage distribution:\")\n",
    "        print(df[target].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TARGET VARIABLE ANALYSIS ===\n",
      "Target variable: V1\n",
      "Number of classes: 7\n",
      "Class distribution:\n",
      "V1\n",
      "1    363\n",
      "2    285\n",
      "3    266\n",
      "4    195\n",
      "5    231\n",
      "6    170\n",
      "7    205\n",
      "Name: count, dtype: int64\n",
      "Class percentages:\n",
      "V1\n",
      "1    21.17\n",
      "2    16.62\n",
      "3    15.51\n",
      "4    11.37\n",
      "5    13.47\n",
      "6     9.91\n",
      "7    11.95\n",
      "Name: count, dtype: float64\n",
      "=== FEATURE ANALYSIS ===\n",
      "Number of features: 201\n",
      "=== CLASS IMBALANCE ANALYSIS ===\n",
      "Smallest class size: 170\n",
      "Largest class size: 363\n",
      "Imbalance ratio: 2.14\n",
      "=== FEATURE STATISTICS BY CLASS ===\n",
      "V102 mean by class:\n",
      "V1\n",
      "1    0.016\n",
      "2    0.048\n",
      "3   -0.148\n",
      "4   -0.039\n",
      "5   -0.052\n",
      "6   -0.075\n",
      "7   -0.067\n",
      "Name: V102, dtype: float64\n",
      "V103 mean by class:\n",
      "V1\n",
      "1   -0.176\n",
      "2    0.129\n",
      "3    1.714\n",
      "4   -1.953\n",
      "5   -0.082\n",
      "6   -5.809\n",
      "7    2.114\n",
      "Name: V103, dtype: float64\n",
      "V104 mean by class:\n",
      "V1\n",
      "1   -4.229\n",
      "2    8.570\n",
      "3   -1.670\n",
      "4    8.290\n",
      "5    3.766\n",
      "6   -1.897\n",
      "7    3.376\n",
      "Name: V104, dtype: float64\n",
      "V105 mean by class:\n",
      "V1\n",
      "1   -4.583\n",
      "2    1.939\n",
      "3    7.581\n",
      "4   -1.854\n",
      "5   -7.151\n",
      "6    3.793\n",
      "7   -5.499\n",
      "Name: V105, dtype: float64\n",
      "V106 mean by class:\n",
      "V1\n",
      "1    0.710\n",
      "2   -0.886\n",
      "3   -1.156\n",
      "4    2.925\n",
      "5   -0.539\n",
      "6   -0.076\n",
      "7    0.961\n",
      "Name: V106, dtype: float64\n",
      "=== DIMENSIONALITY REDUCTION ===\n",
      "Performing PCA...\n",
      "=== VISUALIZATIONS SAVED ===\n",
      "1. target_distribution.png - Distribution of cancer types\n",
      "2. correlation_heatmap.png - Feature correlation matrix\n",
      "3. pca_visualization.png - PCA visualization of samples\n",
      "4. feature_boxplots.png - Feature distribution by cancer type\n",
      "=== SUMMARY ===\n",
      "n_samples: 1715\n",
      "n_features: 201\n",
      "n_classes: 7\n",
      "class_distribution: {1: 363, 2: 285, 3: 266, 4: 195, 5: 231, 6: 170, 7: 205}\n",
      "imbalance_ratio: 2.135294117647059\n",
      "features_with_high_variance: ['V104', 'V105', 'V107', 'V116', 'V117', 'V120', 'V125', 'V130', 'V137', 'V139', 'V146', 'V147', 'V148', 'V2', 'V5', 'V16', 'V17', 'V22', 'V27', 'V33', 'V39', 'V49', 'V55', 'V57', 'V68', 'V70', 'V72', 'V76', 'V80', 'V83', 'V84', 'V86', 'V88', 'V93', 'V94', 'V155', 'V157', 'V159', 'V163', 'V167', 'V169', 'V171', 'V174', 'V179', 'V180', 'V186', 'V191', 'V195', 'V199']\n"
     ]
    }
   ],
   "source": [
    "# Identify the target variable (V1) and features\n",
    "target = 'V1'\n",
    "features = [col for col in df.columns if col != target]\n",
    "\n",
    "print(\"=== TARGET VARIABLE ANALYSIS ===\")\n",
    "print(f\"\\\n",
    "Target variable: {target}\")\n",
    "print(f\"Number of classes: {df[target].nunique()}\")\n",
    "print(f\"\\\n",
    "Class distribution:\")\n",
    "class_counts = df[target].value_counts().sort_index()\n",
    "print(class_counts)\n",
    "print(f\"\\\n",
    "Class percentages:\")\n",
    "print((class_counts / len(df) * 100).round(2))\n",
    "\n",
    "# Create visualizations directory\n",
    "import os\n",
    "if not os.path.exists('visualizations'):\n",
    "    os.makedirs('visualizations')\n",
    "\n",
    "# 1. Target distribution plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = class_counts.plot(kind='bar', color='steelblue', alpha=0.8)\n",
    "plt.title('Distribution of Cancer Types', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Cancer Type (Class)', fontsize=12)\n",
    "plt.ylabel('Number of Samples', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    ax.text(i, v + 5, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. Feature correlation analysis\n",
    "print(\"\\\n",
    "=== FEATURE ANALYSIS ===\")\n",
    "print(f\"Number of features: {len(features)}\")\n",
    "\n",
    "# Calculate correlation matrix for a subset of features (too many to visualize all)\n",
    "subset_features = features[:30]  # First 30 features\n",
    "correlation_matrix = df[subset_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix (First 30 Features)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 3. Class imbalance check\n",
    "print(\"\\\n",
    "=== CLASS IMBALANCE ANALYSIS ===\")\n",
    "min_class_size = class_counts.min()\n",
    "max_class_size = class_counts.max()\n",
    "imbalance_ratio = max_class_size / min_class_size\n",
    "print(f\"Smallest class size: {min_class_size}\")\n",
    "print(f\"Largest class size: {max_class_size}\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "# 4. Feature statistics by class\n",
    "print(\"\\\n",
    "=== FEATURE STATISTICS BY CLASS ===\")\n",
    "# Calculate mean of first few features by class\n",
    "sample_features = features[:5]\n",
    "for feature in sample_features:\n",
    "    print(f\"\\\n",
    "{feature} mean by class:\")\n",
    "    print(df.groupby(target)[feature].mean().round(3))\n",
    "\n",
    "# 5. Dimensionality reduction for visualization\n",
    "print(\"\\\n",
    "=== DIMENSIONALITY REDUCTION ===\")\n",
    "print(\"Performing PCA...\")\n",
    "\n",
    "# Prepare data\n",
    "X = df[features].values\n",
    "y = df[target].values\n",
    "\n",
    "# PCA with 2 components\n",
    "pca = PCA(n_components=6, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(X_pca[:, i*2], X_pca[:, i*2+1], c=y, cmap='viridis', alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "    plt.colorbar(scatter, label='Cancer Type')\n",
    "    plt.xlabel(f'PC{i*2} ({pca.explained_variance_ratio_[i*2]:.2%} variance)', fontsize=12)\n",
    "    plt.ylabel(f'PC{i*2+1} ({pca.explained_variance_ratio_[i*2+1]:.2%} variance)', fontsize=12)\n",
    "    plt.title('PCA Visualization of Cancer Types', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'visualizations/pca_visualization{i}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# 6. Box plots for feature distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(features[:6]):\n",
    "    df.boxplot(column=feature, by=target, ax=axes[i])\n",
    "    axes[i].set_title(f'{feature} by Cancer Type')\n",
    "    axes[i].set_xlabel('Cancer Type')\n",
    "    axes[i].set_ylabel(feature)\n",
    "\n",
    "plt.suptitle('Feature Distribution by Cancer Type', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/feature_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\\n",
    "=== VISUALIZATIONS SAVED ===\")\n",
    "print(\"1. target_distribution.png - Distribution of cancer types\")\n",
    "print(\"2. correlation_heatmap.png - Feature correlation matrix\")\n",
    "print(\"3. pca_visualization.png - PCA visualization of samples\")\n",
    "print(\"4. feature_boxplots.png - Feature distribution by cancer type\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats = {\n",
    "    'n_samples': len(df),\n",
    "    'n_features': len(features),\n",
    "    'n_classes': df[target].nunique(),\n",
    "    'class_distribution': class_counts.to_dict(),\n",
    "    'imbalance_ratio': imbalance_ratio,\n",
    "    'features_with_high_variance': [col for col in features if df[col].std() > 50]\n",
    "}\n",
    "\n",
    "print(\"\\\n",
    "=== SUMMARY ===\")\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
