{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing recall and specificity across 10 folds\n",
      "======================================================================\n",
      "\n",
      "RECALL (mean ± std)\n",
      "----------------------------------------------------------------------\n",
      "  Class            NN           SVM            RF           QDA           KNN            LR\n",
      "Class 1 0.901 ± 0.048 0.948 ± 0.031 0.939 ± 0.021 0.948 ± 0.019 0.956 ± 0.033 0.920 ± 0.031\n",
      "Class 2 0.758 ± 0.044 0.758 ± 0.046 0.765 ± 0.033 0.698 ± 0.064 0.754 ± 0.035 0.737 ± 0.044\n",
      "Class 3 0.883 ± 0.053 0.887 ± 0.037 0.860 ± 0.052 0.891 ± 0.060 0.823 ± 0.065 0.831 ± 0.054\n",
      "Class 4 0.841 ± 0.115 0.882 ± 0.104 0.799 ± 0.116 0.825 ± 0.080 0.814 ± 0.107 0.814 ± 0.104\n",
      "Class 5 0.909 ± 0.057 0.935 ± 0.035 0.918 ± 0.030 0.957 ± 0.034 0.939 ± 0.040 0.896 ± 0.035\n",
      "Class 6 0.812 ± 0.101 0.853 ± 0.084 0.765 ± 0.102 0.894 ± 0.035 0.776 ± 0.120 0.782 ± 0.091\n",
      "Class 7 0.936 ± 0.039 0.951 ± 0.031 0.941 ± 0.042 0.980 ± 0.024 0.951 ± 0.043 0.931 ± 0.050\n",
      "\n",
      "\n",
      "SPECIFICITY (mean ± std)\n",
      "----------------------------------------------------------------------\n",
      "  Class            NN           SVM            RF           QDA           KNN            LR\n",
      "Class 1 0.951 ± 0.012 0.948 ± 0.018 0.936 ± 0.014 0.954 ± 0.011 0.939 ± 0.015 0.950 ± 0.008\n",
      "Class 2 0.964 ± 0.017 0.971 ± 0.015 0.971 ± 0.011 0.978 ± 0.011 0.979 ± 0.013 0.948 ± 0.018\n",
      "Class 3 0.977 ± 0.012 0.984 ± 0.009 0.974 ± 0.011 0.992 ± 0.006 0.988 ± 0.008 0.983 ± 0.009\n",
      "Class 4 0.985 ± 0.008 0.991 ± 0.007 0.990 ± 0.006 0.994 ± 0.006 0.990 ± 0.007 0.982 ± 0.007\n",
      "Class 5 0.982 ± 0.010 0.987 ± 0.007 0.983 ± 0.012 0.977 ± 0.012 0.973 ± 0.014 0.980 ± 0.010\n",
      "Class 6 0.989 ± 0.007 0.990 ± 0.006 0.988 ± 0.005 0.986 ± 0.008 0.987 ± 0.005 0.987 ± 0.008\n",
      "Class 7 0.989 ± 0.010 0.995 ± 0.005 0.992 ± 0.005 0.979 ± 0.014 0.982 ± 0.009 0.989 ± 0.008\n",
      "\n",
      "\n",
      "CLASS DIFFICULTY RANKING - RECALL (based on average recall across all models):\n",
      "  1. Class 7: 0.949\n",
      "  2. Class 1: 0.935\n",
      "  3. Class 5: 0.926\n",
      "  4. Class 3: 0.862\n",
      "  5. Class 4: 0.829\n",
      "  6. Class 6: 0.814\n",
      "  7. Class 2: 0.745\n",
      "\n",
      "\n",
      "CLASS DIFFICULTY RANKING - SPECIFICITY (based on average specificity across all models):\n",
      "  1. Class 4: 0.989\n",
      "  2. Class 6: 0.988\n",
      "  3. Class 7: 0.988\n",
      "  4. Class 3: 0.983\n",
      "  5. Class 5: 0.980\n",
      "  6. Class 2: 0.968\n",
      "  7. Class 1: 0.947\n",
      "\n",
      "\n",
      "BEST MODEL FOR EACH CLASS - RECALL:\n",
      "  Class 1: KNN (0.956)\n",
      "  Class 2: RF (0.765)\n",
      "  Class 3: QDA (0.891)\n",
      "  Class 4: SVM (0.882)\n",
      "  Class 5: QDA (0.957)\n",
      "  Class 6: QDA (0.894)\n",
      "  Class 7: QDA (0.980)\n",
      "\n",
      "\n",
      "BEST MODEL FOR EACH CLASS - SPECIFICITY:\n",
      "  Class 1: QDA (0.954)\n",
      "  Class 2: KNN (0.979)\n",
      "  Class 3: QDA (0.992)\n",
      "  Class 4: QDA (0.994)\n",
      "  Class 5: SVM (0.987)\n",
      "  Class 6: SVM (0.990)\n",
      "  Class 7: SVM (0.995)\n",
      "\n",
      "\n",
      "MODEL STABILITY RANKING - RECALL (based on average std across classes):\n",
      "  1. QDA: 0.0450\n",
      "  2. SVM: 0.0527\n",
      "  3. RF: 0.0566\n",
      "  4. LR: 0.0584\n",
      "  5. KNN: 0.0633\n",
      "  6. NN: 0.0654\n",
      "\n",
      "\n",
      "BALANCED PERFORMANCE ANALYSIS (Average of Recall and Specificity):\n",
      "\n",
      "Class ranking by balanced performance:\n",
      "  1. Class 7: 0.968\n",
      "  2. Class 5: 0.953\n",
      "  3. Class 1: 0.941\n",
      "  4. Class 3: 0.923\n",
      "  5. Class 4: 0.909\n",
      "  6. Class 6: 0.901\n",
      "  7. Class 2: 0.857\n",
      "\n",
      "\n",
      "MODEL STABILITY RANKING - SPECIFICITY (based on average std across classes):\n",
      "  1. RF: 0.0094\n",
      "  2. SVM: 0.0096\n",
      "  3. LR: 0.0097\n",
      "  4. QDA: 0.0097\n",
      "  5. KNN: 0.0101\n",
      "  6. NN: 0.0109\n",
      "\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Completed! Saved:\n",
      "- 24 numpy arrays (mean and std for each model and metric)\n",
      "- 4 CSV tables (recall and specificity, both with full and short model names)\n",
      "\n",
      "Files saved:\n",
      "- Numpy arrays: {model}_{metric}_mean.npy and {model}_{metric}_std.npy\n",
      "- CSV tables: recall_table.csv, specificity_table.csv (with short model names)\n",
      "- CSV tables: recall_table_full.csv, specificity_table_full.csv (with full model names)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Per-Class Recall and Specificity Analysis - Simplified Version\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_ROOT = 'output'\n",
    "METRICS_DIR = os.path.join(OUTPUT_ROOT, 'metrics')\n",
    "MODEL_SET = ['FS_PCA_NN', 'FS_PCA_SVM', 'RF', 'FS_PCA_QDA', 'FS_PCA_KNN', 'FS_PCA_LR']\n",
    "\n",
    "# Model display names\n",
    "MODEL_DISPLAY = {\n",
    "    'FS_PCA_NN': 'NN',\n",
    "    'FS_PCA_SVM': 'SVM',\n",
    "    'RF': 'RF',\n",
    "    'FS_PCA_QDA': 'QDA', \n",
    "    'FS_PCA_KNN': 'KNN',\n",
    "    'FS_PCA_LR': 'LR'\n",
    "}\n",
    "\n",
    "# Auto-detect number of folds\n",
    "def detect_n_folds():\n",
    "    if not os.path.exists(METRICS_DIR):\n",
    "        return 5\n",
    "    max_fold = 0\n",
    "    for model in MODEL_SET:\n",
    "        fold = 1\n",
    "        while os.path.exists(os.path.join(METRICS_DIR, f\"per_class_recall_{model}_{fold}.npy\")):\n",
    "            max_fold = max(max_fold, fold)\n",
    "            fold += 1\n",
    "    return max_fold if max_fold > 0 else 5\n",
    "\n",
    "N_FOLDS = detect_n_folds()\n",
    "\n",
    "def main():\n",
    "    print(f\"Analyzing recall and specificity across {N_FOLDS} folds\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Process recall\n",
    "    recall_results = {}\n",
    "    for model_name in MODEL_SET:\n",
    "        values = []\n",
    "        for fold_idx in range(1, N_FOLDS + 1):\n",
    "            filepath = os.path.join(METRICS_DIR, f\"per_class_recall_{model_name}_{fold_idx}.npy\")\n",
    "            if os.path.exists(filepath):\n",
    "                values.append(np.load(filepath))\n",
    "        \n",
    "        if values:\n",
    "            values = np.array(values)\n",
    "            mean_vals = np.mean(values, axis=0)\n",
    "            std_vals = np.std(values, axis=0)\n",
    "            \n",
    "            # Save arrays\n",
    "            np.save(f\"{model_name}_recall_mean.npy\", mean_vals)\n",
    "            np.save(f\"{model_name}_recall_std.npy\", std_vals)\n",
    "            \n",
    "            recall_results[model_name] = {'mean': mean_vals, 'std': std_vals}\n",
    "    \n",
    "    # Create recall table\n",
    "    recall_table_data = []\n",
    "    for class_idx in range(7):\n",
    "        row = [f\"Class {class_idx + 1}\"]\n",
    "        for model in MODEL_SET:\n",
    "            if model in recall_results:\n",
    "                m = recall_results[model]['mean'][class_idx]\n",
    "                s = recall_results[model]['std'][class_idx]\n",
    "                row.append(f\"{m:.3f} ± {s:.3f}\")\n",
    "            else:\n",
    "                row.append(\"N/A\")\n",
    "        recall_table_data.append(row)\n",
    "    \n",
    "    # 创建两个版本的DataFrame - 一个用于保存（完整模型名），一个用于显示（简短模型名）\n",
    "    recall_df = pd.DataFrame(recall_table_data, columns=['Class'] + MODEL_SET)\n",
    "    recall_df_display = pd.DataFrame(recall_table_data, columns=['Class'] + [MODEL_DISPLAY[m] for m in MODEL_SET])\n",
    "    \n",
    "    print(\"\\nRECALL (mean ± std)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(recall_df_display.to_string(index=False))\n",
    "    recall_df.to_csv('recall_table_full.csv', index=False)\n",
    "    recall_df_display.to_csv('recall_table.csv', index=False)\n",
    "    \n",
    "    # Process specificity\n",
    "    spec_results = {}\n",
    "    for model_name in MODEL_SET:\n",
    "        values = []\n",
    "        for fold_idx in range(1, N_FOLDS + 1):\n",
    "            filepath = os.path.join(METRICS_DIR, f\"per_class_specificity_{model_name}_{fold_idx}.npy\")\n",
    "            if os.path.exists(filepath):\n",
    "                values.append(np.load(filepath))\n",
    "        \n",
    "        if values:\n",
    "            values = np.array(values)\n",
    "            mean_vals = np.mean(values, axis=0)\n",
    "            std_vals = np.std(values, axis=0)\n",
    "            \n",
    "            # Save arrays\n",
    "            np.save(f\"{model_name}_specificity_mean.npy\", mean_vals)\n",
    "            np.save(f\"{model_name}_specificity_std.npy\", std_vals)\n",
    "            \n",
    "            spec_results[model_name] = {'mean': mean_vals, 'std': std_vals}\n",
    "    \n",
    "    # Create specificity table\n",
    "    spec_table_data = []\n",
    "    for class_idx in range(7):\n",
    "        row = [f\"Class {class_idx + 1}\"]\n",
    "        for model in MODEL_SET:\n",
    "            if model in spec_results:\n",
    "                m = spec_results[model]['mean'][class_idx]\n",
    "                s = spec_results[model]['std'][class_idx]\n",
    "                row.append(f\"{m:.3f} ± {s:.3f}\")\n",
    "            else:\n",
    "                row.append(\"N/A\")\n",
    "        spec_table_data.append(row)\n",
    "    \n",
    "    # 创建两个版本的DataFrame - 一个用于保存（完整模型名），一个用于显示（简短模型名）\n",
    "    spec_df = pd.DataFrame(spec_table_data, columns=['Class'] + MODEL_SET)\n",
    "    spec_df_display = pd.DataFrame(spec_table_data, columns=['Class'] + [MODEL_DISPLAY[m] for m in MODEL_SET])\n",
    "    \n",
    "    print(\"\\n\\nSPECIFICITY (mean ± std)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(spec_df_display.to_string(index=False))\n",
    "    spec_df.to_csv('specificity_table_full.csv', index=False)\n",
    "    spec_df_display.to_csv('specificity_table.csv', index=False)\n",
    "    \n",
    "    # Class difficulty analysis for RECALL\n",
    "    print(\"\\n\\nCLASS DIFFICULTY RANKING - RECALL (based on average recall across all models):\")\n",
    "    class_difficulties_recall = []\n",
    "    \n",
    "    for class_idx in range(7):\n",
    "        class_recalls = []\n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in recall_results:\n",
    "                class_recalls.append(recall_results[model_name]['mean'][class_idx])\n",
    "        avg_recall = np.mean(class_recalls) if class_recalls else 0\n",
    "        class_difficulties_recall.append((f\"Class {class_idx + 1}\", avg_recall))\n",
    "    \n",
    "    class_difficulties_recall.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for rank, (class_name, avg_recall) in enumerate(class_difficulties_recall, 1):\n",
    "        print(f\"  {rank}. {class_name}: {avg_recall:.3f}\")\n",
    "    \n",
    "    # Class difficulty analysis for SPECIFICITY\n",
    "    print(\"\\n\\nCLASS DIFFICULTY RANKING - SPECIFICITY (based on average specificity across all models):\")\n",
    "    class_difficulties_spec = []\n",
    "    \n",
    "    for class_idx in range(7):\n",
    "        class_specs = []\n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in spec_results:\n",
    "                class_specs.append(spec_results[model_name]['mean'][class_idx])\n",
    "        avg_spec = np.mean(class_specs) if class_specs else 0\n",
    "        class_difficulties_spec.append((f\"Class {class_idx + 1}\", avg_spec))\n",
    "    \n",
    "    class_difficulties_spec.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for rank, (class_name, avg_spec) in enumerate(class_difficulties_spec, 1):\n",
    "        print(f\"  {rank}. {class_name}: {avg_spec:.3f}\")\n",
    "    \n",
    "    # Best model for each class - RECALL\n",
    "    print(\"\\n\\nBEST MODEL FOR EACH CLASS - RECALL:\")\n",
    "    for class_idx in range(7):\n",
    "        best_recall = -1\n",
    "        best_model = \"\"\n",
    "        \n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in recall_results:\n",
    "                recall_val = recall_results[model_name]['mean'][class_idx]\n",
    "                if recall_val > best_recall:\n",
    "                    best_recall = recall_val\n",
    "                    best_model = MODEL_DISPLAY.get(model_name, model_name)\n",
    "        \n",
    "        print(f\"  Class {class_idx + 1}: {best_model} ({best_recall:.3f})\")\n",
    "    \n",
    "    # Best model for each class - SPECIFICITY\n",
    "    print(\"\\n\\nBEST MODEL FOR EACH CLASS - SPECIFICITY:\")\n",
    "    for class_idx in range(7):\n",
    "        best_spec = -1\n",
    "        best_model = \"\"\n",
    "        \n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in spec_results:\n",
    "                spec_val = spec_results[model_name]['mean'][class_idx]\n",
    "                if spec_val > best_spec:\n",
    "                    best_spec = spec_val\n",
    "                    best_model = MODEL_DISPLAY.get(model_name, model_name)\n",
    "        \n",
    "        print(f\"  Class {class_idx + 1}: {best_model} ({best_spec:.3f})\")\n",
    "    \n",
    "    # Model stability ranking\n",
    "    print(\"\\n\\nMODEL STABILITY RANKING - RECALL (based on average std across classes):\")\n",
    "    stability_recall = []\n",
    "    \n",
    "    for model_name in MODEL_SET:\n",
    "        if model_name in recall_results:\n",
    "            avg_std = np.mean(recall_results[model_name]['std'])\n",
    "            stability_recall.append((MODEL_DISPLAY.get(model_name, model_name), avg_std))\n",
    "    \n",
    "    stability_recall.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for rank, (model, avg_std) in enumerate(stability_recall, 1):\n",
    "        print(f\"  {rank}. {model}: {avg_std:.4f}\")\n",
    "    \n",
    "    # Balanced performance analysis\n",
    "    print(\"\\n\\nBALANCED PERFORMANCE ANALYSIS (Average of Recall and Specificity):\")\n",
    "    balanced_scores = []\n",
    "    \n",
    "    for class_idx in range(7):\n",
    "        class_balanced = []\n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in recall_results and model_name in spec_results:\n",
    "                balanced = (recall_results[model_name]['mean'][class_idx] + \n",
    "                           spec_results[model_name]['mean'][class_idx]) / 2\n",
    "                class_balanced.append(balanced)\n",
    "        avg_balanced = np.mean(class_balanced) if class_balanced else 0\n",
    "        balanced_scores.append((f\"Class {class_idx + 1}\", avg_balanced))\n",
    "    \n",
    "    balanced_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nClass ranking by balanced performance:\")\n",
    "    for rank, (class_name, score) in enumerate(balanced_scores, 1):\n",
    "        print(f\"  {rank}. {class_name}: {score:.3f}\")\n",
    "    \n",
    "    print(\"\\n\\nMODEL STABILITY RANKING - SPECIFICITY (based on average std across classes):\")\n",
    "    stability_spec = []\n",
    "    \n",
    "    for model_name in MODEL_SET:\n",
    "        if model_name in spec_results:\n",
    "            avg_std = np.mean(spec_results[model_name]['std'])\n",
    "            stability_spec.append((MODEL_DISPLAY.get(model_name, model_name), avg_std))\n",
    "    \n",
    "    stability_spec.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for rank, (model, avg_std) in enumerate(stability_spec, 1):\n",
    "        print(f\"  {rank}. {model}: {avg_std:.4f}\")\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\" * 70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Completed! Saved:\")\n",
    "    print(f\"- {2 * len(MODEL_SET) * 2} numpy arrays (mean and std for each model and metric)\")\n",
    "    print(f\"- 4 CSV tables (recall and specificity, both with full and short model names)\")\n",
    "    print(\"\\nFiles saved:\")\n",
    "    print(\"- Numpy arrays: {model}_{metric}_mean.npy and {model}_{metric}_std.npy\")\n",
    "    print(\"- CSV tables: recall_table.csv, specificity_table.csv (with short model names)\")\n",
    "    print(\"- CSV tables: recall_table_full.csv, specificity_table_full.csv (with full model names)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
