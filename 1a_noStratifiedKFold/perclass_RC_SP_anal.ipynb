{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing recall and specificity across 10 folds\n",
      "======================================================================\n",
      "\n",
      "RECALL (mean ± std)\n",
      "----------------------------------------------------------------------\n",
      "  Class            NN           SVM            RF           QDA           KNN            LR\n",
      "Class 1 0.862 ± 0.063 0.937 ± 0.062 0.937 ± 0.058 0.945 ± 0.051 0.940 ± 0.038 0.914 ± 0.063\n",
      "Class 2 0.732 ± 0.065 0.738 ± 0.070 0.760 ± 0.066 0.684 ± 0.090 0.763 ± 0.066 0.718 ± 0.045\n",
      "Class 3 0.858 ± 0.041 0.877 ± 0.070 0.860 ± 0.054 0.874 ± 0.068 0.788 ± 0.082 0.822 ± 0.057\n",
      "Class 4 0.833 ± 0.053 0.875 ± 0.049 0.818 ± 0.088 0.838 ± 0.068 0.781 ± 0.099 0.832 ± 0.063\n",
      "Class 5 0.934 ± 0.052 0.949 ± 0.059 0.948 ± 0.059 0.956 ± 0.049 0.935 ± 0.068 0.910 ± 0.074\n",
      "Class 6 0.806 ± 0.098 0.818 ± 0.104 0.778 ± 0.112 0.895 ± 0.090 0.786 ± 0.108 0.781 ± 0.120\n",
      "Class 7 0.954 ± 0.050 0.935 ± 0.056 0.935 ± 0.056 0.980 ± 0.034 0.939 ± 0.058 0.915 ± 0.052\n",
      "\n",
      "\n",
      "SPECIFICITY (mean ± std)\n",
      "----------------------------------------------------------------------\n",
      "  Class            NN           SVM            RF           QDA           KNN            LR\n",
      "Class 1 0.955 ± 0.011 0.953 ± 0.013 0.937 ± 0.022 0.951 ± 0.014 0.944 ± 0.016 0.950 ± 0.009\n",
      "Class 2 0.953 ± 0.020 0.964 ± 0.018 0.976 ± 0.013 0.977 ± 0.013 0.973 ± 0.012 0.948 ± 0.018\n",
      "Class 3 0.982 ± 0.015 0.984 ± 0.012 0.973 ± 0.010 0.992 ± 0.006 0.987 ± 0.010 0.981 ± 0.012\n",
      "Class 4 0.983 ± 0.009 0.990 ± 0.008 0.993 ± 0.008 0.994 ± 0.007 0.990 ± 0.006 0.983 ± 0.009\n",
      "Class 5 0.982 ± 0.008 0.986 ± 0.008 0.982 ± 0.008 0.981 ± 0.011 0.968 ± 0.017 0.979 ± 0.012\n",
      "Class 6 0.981 ± 0.013 0.986 ± 0.009 0.990 ± 0.007 0.984 ± 0.010 0.984 ± 0.013 0.985 ± 0.010\n",
      "Class 7 0.989 ± 0.007 0.993 ± 0.005 0.991 ± 0.007 0.978 ± 0.009 0.982 ± 0.008 0.987 ± 0.010\n",
      "\n",
      "\n",
      "CLASS DIFFICULTY RANKING - RECALL (based on average recall across all models):\n",
      "  1. Class 7: 0.943\n",
      "  2. Class 5: 0.939\n",
      "  3. Class 1: 0.922\n",
      "  4. Class 3: 0.846\n",
      "  5. Class 4: 0.830\n",
      "  6. Class 6: 0.811\n",
      "  7. Class 2: 0.733\n",
      "\n",
      "\n",
      "CLASS DIFFICULTY RANKING - SPECIFICITY (based on average specificity across all models):\n",
      "  1. Class 4: 0.989\n",
      "  2. Class 7: 0.987\n",
      "  3. Class 6: 0.985\n",
      "  4. Class 3: 0.983\n",
      "  5. Class 5: 0.980\n",
      "  6. Class 2: 0.965\n",
      "  7. Class 1: 0.948\n",
      "\n",
      "\n",
      "BEST MODEL FOR EACH CLASS - RECALL:\n",
      "  Class 1: QDA (0.945)\n",
      "  Class 2: KNN (0.763)\n",
      "  Class 3: SVM (0.877)\n",
      "  Class 4: SVM (0.875)\n",
      "  Class 5: QDA (0.956)\n",
      "  Class 6: QDA (0.895)\n",
      "  Class 7: QDA (0.980)\n",
      "\n",
      "\n",
      "BEST MODEL FOR EACH CLASS - SPECIFICITY:\n",
      "  Class 1: NN (0.955)\n",
      "  Class 2: QDA (0.977)\n",
      "  Class 3: QDA (0.992)\n",
      "  Class 4: QDA (0.994)\n",
      "  Class 5: SVM (0.986)\n",
      "  Class 6: RF (0.990)\n",
      "  Class 7: SVM (0.993)\n",
      "\n",
      "\n",
      "MODEL STABILITY RANKING - RECALL (based on average std across classes):\n",
      "  1. NN: 0.0602\n",
      "  2. QDA: 0.0644\n",
      "  3. SVM: 0.0670\n",
      "  4. LR: 0.0679\n",
      "  5. RF: 0.0704\n",
      "  6. KNN: 0.0742\n",
      "\n",
      "\n",
      "BALANCED PERFORMANCE ANALYSIS (Average of Recall and Specificity):\n",
      "\n",
      "Class ranking by balanced performance:\n",
      "  1. Class 7: 0.965\n",
      "  2. Class 5: 0.959\n",
      "  3. Class 1: 0.935\n",
      "  4. Class 3: 0.915\n",
      "  5. Class 4: 0.909\n",
      "  6. Class 6: 0.898\n",
      "  7. Class 2: 0.849\n",
      "\n",
      "\n",
      "MODEL STABILITY RANKING - SPECIFICITY (based on average std across classes):\n",
      "  1. QDA: 0.0100\n",
      "  2. SVM: 0.0106\n",
      "  3. RF: 0.0109\n",
      "  4. LR: 0.0115\n",
      "  5. NN: 0.0116\n",
      "  6. KNN: 0.0119\n",
      "\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Completed! Saved:\n",
      "- 24 numpy arrays (mean and std for each model and metric)\n",
      "- 4 CSV tables (recall and specificity, both with full and short model names)\n",
      "\n",
      "Files saved:\n",
      "- Numpy arrays: {model}_{metric}_mean.npy and {model}_{metric}_std.npy\n",
      "- CSV tables: recall_table.csv, specificity_table.csv (with short model names)\n",
      "- CSV tables: recall_table_full.csv, specificity_table_full.csv (with full model names)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Per-Class Recall and Specificity Analysis - Simplified Version\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_ROOT = 'output'\n",
    "METRICS_DIR = os.path.join(OUTPUT_ROOT, 'metrics')\n",
    "MODEL_SET = ['FS_PCA_NN', 'FS_PCA_SVM', 'RF', 'FS_PCA_QDA', 'FS_PCA_KNN', 'FS_PCA_LR']\n",
    "\n",
    "# Model display names\n",
    "MODEL_DISPLAY = {\n",
    "    'FS_PCA_NN': 'NN',\n",
    "    'FS_PCA_SVM': 'SVM',\n",
    "    'RF': 'RF',\n",
    "    'FS_PCA_QDA': 'QDA', \n",
    "    'FS_PCA_KNN': 'KNN',\n",
    "    'FS_PCA_LR': 'LR'\n",
    "}\n",
    "\n",
    "# Auto-detect number of folds\n",
    "def detect_n_folds():\n",
    "    if not os.path.exists(METRICS_DIR):\n",
    "        return 5\n",
    "    max_fold = 0\n",
    "    for model in MODEL_SET:\n",
    "        fold = 1\n",
    "        while os.path.exists(os.path.join(METRICS_DIR, f\"per_class_recall_{model}_{fold}.npy\")):\n",
    "            max_fold = max(max_fold, fold)\n",
    "            fold += 1\n",
    "    return max_fold if max_fold > 0 else 5\n",
    "\n",
    "N_FOLDS = detect_n_folds()\n",
    "\n",
    "def main():\n",
    "    print(f\"Analyzing recall and specificity across {N_FOLDS} folds\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Process recall\n",
    "    recall_results = {}\n",
    "    for model_name in MODEL_SET:\n",
    "        values = []\n",
    "        for fold_idx in range(1, N_FOLDS + 1):\n",
    "            filepath = os.path.join(METRICS_DIR, f\"per_class_recall_{model_name}_{fold_idx}.npy\")\n",
    "            if os.path.exists(filepath):\n",
    "                values.append(np.load(filepath))\n",
    "        \n",
    "        if values:\n",
    "            values = np.array(values)\n",
    "            mean_vals = np.mean(values, axis=0)\n",
    "            std_vals = np.std(values, axis=0)\n",
    "            \n",
    "            # Save arrays\n",
    "            np.save(f\"{model_name}_recall_mean.npy\", mean_vals)\n",
    "            np.save(f\"{model_name}_recall_std.npy\", std_vals)\n",
    "            \n",
    "            recall_results[model_name] = {'mean': mean_vals, 'std': std_vals}\n",
    "    \n",
    "    # Create recall table\n",
    "    recall_table_data = []\n",
    "    for class_idx in range(7):\n",
    "        row = [f\"Class {class_idx + 1}\"]\n",
    "        for model in MODEL_SET:\n",
    "            if model in recall_results:\n",
    "                m = recall_results[model]['mean'][class_idx]\n",
    "                s = recall_results[model]['std'][class_idx]\n",
    "                row.append(f\"{m:.3f} ± {s:.3f}\")\n",
    "            else:\n",
    "                row.append(\"N/A\")\n",
    "        recall_table_data.append(row)\n",
    "    \n",
    "    # 创建两个版本的DataFrame - 一个用于保存（完整模型名），一个用于显示（简短模型名）\n",
    "    recall_df = pd.DataFrame(recall_table_data, columns=['Class'] + MODEL_SET)\n",
    "    recall_df_display = pd.DataFrame(recall_table_data, columns=['Class'] + [MODEL_DISPLAY[m] for m in MODEL_SET])\n",
    "    \n",
    "    print(\"\\nRECALL (mean ± std)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(recall_df_display.to_string(index=False))\n",
    "    recall_df.to_csv('recall_table_full.csv', index=False)\n",
    "    recall_df_display.to_csv('recall_table.csv', index=False)\n",
    "    \n",
    "    # Process specificity\n",
    "    spec_results = {}\n",
    "    for model_name in MODEL_SET:\n",
    "        values = []\n",
    "        for fold_idx in range(1, N_FOLDS + 1):\n",
    "            filepath = os.path.join(METRICS_DIR, f\"per_class_specificity_{model_name}_{fold_idx}.npy\")\n",
    "            if os.path.exists(filepath):\n",
    "                values.append(np.load(filepath))\n",
    "        \n",
    "        if values:\n",
    "            values = np.array(values)\n",
    "            mean_vals = np.mean(values, axis=0)\n",
    "            std_vals = np.std(values, axis=0)\n",
    "            \n",
    "            # Save arrays\n",
    "            np.save(f\"{model_name}_specificity_mean.npy\", mean_vals)\n",
    "            np.save(f\"{model_name}_specificity_std.npy\", std_vals)\n",
    "            \n",
    "            spec_results[model_name] = {'mean': mean_vals, 'std': std_vals}\n",
    "    \n",
    "    # Create specificity table\n",
    "    spec_table_data = []\n",
    "    for class_idx in range(7):\n",
    "        row = [f\"Class {class_idx + 1}\"]\n",
    "        for model in MODEL_SET:\n",
    "            if model in spec_results:\n",
    "                m = spec_results[model]['mean'][class_idx]\n",
    "                s = spec_results[model]['std'][class_idx]\n",
    "                row.append(f\"{m:.3f} ± {s:.3f}\")\n",
    "            else:\n",
    "                row.append(\"N/A\")\n",
    "        spec_table_data.append(row)\n",
    "    \n",
    "    # 创建两个版本的DataFrame - 一个用于保存（完整模型名），一个用于显示（简短模型名）\n",
    "    spec_df = pd.DataFrame(spec_table_data, columns=['Class'] + MODEL_SET)\n",
    "    spec_df_display = pd.DataFrame(spec_table_data, columns=['Class'] + [MODEL_DISPLAY[m] for m in MODEL_SET])\n",
    "    \n",
    "    print(\"\\n\\nSPECIFICITY (mean ± std)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(spec_df_display.to_string(index=False))\n",
    "    spec_df.to_csv('specificity_table_full.csv', index=False)\n",
    "    spec_df_display.to_csv('specificity_table.csv', index=False)\n",
    "    \n",
    "    # Class difficulty analysis for RECALL\n",
    "    print(\"\\n\\nCLASS DIFFICULTY RANKING - RECALL (based on average recall across all models):\")\n",
    "    class_difficulties_recall = []\n",
    "    \n",
    "    for class_idx in range(7):\n",
    "        class_recalls = []\n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in recall_results:\n",
    "                class_recalls.append(recall_results[model_name]['mean'][class_idx])\n",
    "        avg_recall = np.mean(class_recalls) if class_recalls else 0\n",
    "        class_difficulties_recall.append((f\"Class {class_idx + 1}\", avg_recall))\n",
    "    \n",
    "    class_difficulties_recall.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for rank, (class_name, avg_recall) in enumerate(class_difficulties_recall, 1):\n",
    "        print(f\"  {rank}. {class_name}: {avg_recall:.3f}\")\n",
    "    \n",
    "    # Class difficulty analysis for SPECIFICITY\n",
    "    print(\"\\n\\nCLASS DIFFICULTY RANKING - SPECIFICITY (based on average specificity across all models):\")\n",
    "    class_difficulties_spec = []\n",
    "    \n",
    "    for class_idx in range(7):\n",
    "        class_specs = []\n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in spec_results:\n",
    "                class_specs.append(spec_results[model_name]['mean'][class_idx])\n",
    "        avg_spec = np.mean(class_specs) if class_specs else 0\n",
    "        class_difficulties_spec.append((f\"Class {class_idx + 1}\", avg_spec))\n",
    "    \n",
    "    class_difficulties_spec.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for rank, (class_name, avg_spec) in enumerate(class_difficulties_spec, 1):\n",
    "        print(f\"  {rank}. {class_name}: {avg_spec:.3f}\")\n",
    "    \n",
    "    # Best model for each class - RECALL\n",
    "    print(\"\\n\\nBEST MODEL FOR EACH CLASS - RECALL:\")\n",
    "    for class_idx in range(7):\n",
    "        best_recall = -1\n",
    "        best_model = \"\"\n",
    "        \n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in recall_results:\n",
    "                recall_val = recall_results[model_name]['mean'][class_idx]\n",
    "                if recall_val > best_recall:\n",
    "                    best_recall = recall_val\n",
    "                    best_model = MODEL_DISPLAY.get(model_name, model_name)\n",
    "        \n",
    "        print(f\"  Class {class_idx + 1}: {best_model} ({best_recall:.3f})\")\n",
    "    \n",
    "    # Best model for each class - SPECIFICITY\n",
    "    print(\"\\n\\nBEST MODEL FOR EACH CLASS - SPECIFICITY:\")\n",
    "    for class_idx in range(7):\n",
    "        best_spec = -1\n",
    "        best_model = \"\"\n",
    "        \n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in spec_results:\n",
    "                spec_val = spec_results[model_name]['mean'][class_idx]\n",
    "                if spec_val > best_spec:\n",
    "                    best_spec = spec_val\n",
    "                    best_model = MODEL_DISPLAY.get(model_name, model_name)\n",
    "        \n",
    "        print(f\"  Class {class_idx + 1}: {best_model} ({best_spec:.3f})\")\n",
    "    \n",
    "    # Model stability ranking\n",
    "    print(\"\\n\\nMODEL STABILITY RANKING - RECALL (based on average std across classes):\")\n",
    "    stability_recall = []\n",
    "    \n",
    "    for model_name in MODEL_SET:\n",
    "        if model_name in recall_results:\n",
    "            avg_std = np.mean(recall_results[model_name]['std'])\n",
    "            stability_recall.append((MODEL_DISPLAY.get(model_name, model_name), avg_std))\n",
    "    \n",
    "    stability_recall.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for rank, (model, avg_std) in enumerate(stability_recall, 1):\n",
    "        print(f\"  {rank}. {model}: {avg_std:.4f}\")\n",
    "    \n",
    "    # Balanced performance analysis\n",
    "    print(\"\\n\\nBALANCED PERFORMANCE ANALYSIS (Average of Recall and Specificity):\")\n",
    "    balanced_scores = []\n",
    "    \n",
    "    for class_idx in range(7):\n",
    "        class_balanced = []\n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in recall_results and model_name in spec_results:\n",
    "                balanced = (recall_results[model_name]['mean'][class_idx] + \n",
    "                           spec_results[model_name]['mean'][class_idx]) / 2\n",
    "                class_balanced.append(balanced)\n",
    "        avg_balanced = np.mean(class_balanced) if class_balanced else 0\n",
    "        balanced_scores.append((f\"Class {class_idx + 1}\", avg_balanced))\n",
    "    \n",
    "    balanced_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nClass ranking by balanced performance:\")\n",
    "    for rank, (class_name, score) in enumerate(balanced_scores, 1):\n",
    "        print(f\"  {rank}. {class_name}: {score:.3f}\")\n",
    "    \n",
    "    print(\"\\n\\nMODEL STABILITY RANKING - SPECIFICITY (based on average std across classes):\")\n",
    "    stability_spec = []\n",
    "    \n",
    "    for model_name in MODEL_SET:\n",
    "        if model_name in spec_results:\n",
    "            avg_std = np.mean(spec_results[model_name]['std'])\n",
    "            stability_spec.append((MODEL_DISPLAY.get(model_name, model_name), avg_std))\n",
    "    \n",
    "    stability_spec.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for rank, (model, avg_std) in enumerate(stability_spec, 1):\n",
    "        print(f\"  {rank}. {model}: {avg_std:.4f}\")\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\" * 70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Completed! Saved:\")\n",
    "    print(f\"- {2 * len(MODEL_SET) * 2} numpy arrays (mean and std for each model and metric)\")\n",
    "    print(f\"- 4 CSV tables (recall and specificity, both with full and short model names)\")\n",
    "    print(\"\\nFiles saved:\")\n",
    "    print(\"- Numpy arrays: {model}_{metric}_mean.npy and {model}_{metric}_std.npy\")\n",
    "    print(\"- CSV tables: recall_table.csv, specificity_table.csv (with short model names)\")\n",
    "    print(\"- CSV tables: recall_table_full.csv, specificity_table_full.csv (with full model names)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
