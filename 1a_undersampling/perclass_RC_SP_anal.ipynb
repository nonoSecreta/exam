{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing recall and specificity across 10 folds\n",
      "======================================================================\n",
      "\n",
      "RECALL (mean ± std)\n",
      "----------------------------------------------------------------------\n",
      "  Class            NN           SVM            RF           QDA           KNN            LR\n",
      "Class 1 0.865 ± 0.075 0.953 ± 0.051 0.882 ± 0.091 0.912 ± 0.054 0.947 ± 0.049 0.829 ± 0.093\n",
      "Class 2 0.735 ± 0.096 0.759 ± 0.116 0.747 ± 0.126 0.676 ± 0.084 0.741 ± 0.124 0.676 ± 0.115\n",
      "Class 3 0.812 ± 0.101 0.841 ± 0.091 0.829 ± 0.093 0.859 ± 0.088 0.759 ± 0.093 0.782 ± 0.129\n",
      "Class 4 0.841 ± 0.059 0.888 ± 0.061 0.865 ± 0.083 0.806 ± 0.079 0.865 ± 0.065 0.853 ± 0.054\n",
      "Class 5 0.906 ± 0.066 0.935 ± 0.055 0.918 ± 0.047 0.965 ± 0.039 0.935 ± 0.041 0.894 ± 0.063\n",
      "Class 6 0.841 ± 0.087 0.859 ± 0.088 0.847 ± 0.080 0.929 ± 0.051 0.835 ± 0.086 0.818 ± 0.110\n",
      "Class 7 0.947 ± 0.061 0.941 ± 0.053 0.947 ± 0.049 0.982 ± 0.027 0.971 ± 0.029 0.935 ± 0.067\n",
      "\n",
      "\n",
      "SPECIFICITY (mean ± std)\n",
      "----------------------------------------------------------------------\n",
      "  Class            NN           SVM            RF           QDA           KNN            LR\n",
      "Class 1 0.964 ± 0.021 0.961 ± 0.015 0.959 ± 0.018 0.965 ± 0.016 0.947 ± 0.017 0.959 ± 0.017\n",
      "Class 2 0.956 ± 0.017 0.970 ± 0.021 0.980 ± 0.015 0.981 ± 0.011 0.982 ± 0.014 0.957 ± 0.027\n",
      "Class 3 0.985 ± 0.010 0.987 ± 0.011 0.971 ± 0.018 0.995 ± 0.007 0.996 ± 0.007 0.982 ± 0.012\n",
      "Class 4 0.983 ± 0.009 0.985 ± 0.011 0.982 ± 0.007 0.993 ± 0.008 0.988 ± 0.011 0.975 ± 0.020\n",
      "Class 5 0.976 ± 0.015 0.984 ± 0.013 0.986 ± 0.014 0.978 ± 0.014 0.973 ± 0.013 0.973 ± 0.016\n",
      "Class 6 0.973 ± 0.020 0.984 ± 0.012 0.975 ± 0.013 0.968 ± 0.021 0.977 ± 0.016 0.972 ± 0.020\n",
      "Class 7 0.987 ± 0.010 0.991 ± 0.007 0.986 ± 0.009 0.975 ± 0.013 0.978 ± 0.014 0.980 ± 0.013\n",
      "\n",
      "\n",
      "CLASS DIFFICULTY RANKING - RECALL (based on average recall across all models):\n",
      "  1. Class 7: 0.954\n",
      "  2. Class 5: 0.925\n",
      "  3. Class 1: 0.898\n",
      "  4. Class 6: 0.855\n",
      "  5. Class 4: 0.853\n",
      "  6. Class 3: 0.814\n",
      "  7. Class 2: 0.723\n",
      "\n",
      "\n",
      "CLASS DIFFICULTY RANKING - SPECIFICITY (based on average specificity across all models):\n",
      "  1. Class 3: 0.986\n",
      "  2. Class 4: 0.985\n",
      "  3. Class 7: 0.983\n",
      "  4. Class 5: 0.978\n",
      "  5. Class 6: 0.975\n",
      "  6. Class 2: 0.971\n",
      "  7. Class 1: 0.959\n",
      "\n",
      "\n",
      "BEST MODEL FOR EACH CLASS - RECALL:\n",
      "  Class 1: SVM (0.953)\n",
      "  Class 2: SVM (0.759)\n",
      "  Class 3: QDA (0.859)\n",
      "  Class 4: SVM (0.888)\n",
      "  Class 5: QDA (0.965)\n",
      "  Class 6: QDA (0.929)\n",
      "  Class 7: QDA (0.982)\n",
      "\n",
      "\n",
      "BEST MODEL FOR EACH CLASS - SPECIFICITY:\n",
      "  Class 1: QDA (0.965)\n",
      "  Class 2: KNN (0.982)\n",
      "  Class 3: KNN (0.996)\n",
      "  Class 4: QDA (0.993)\n",
      "  Class 5: RF (0.986)\n",
      "  Class 6: SVM (0.984)\n",
      "  Class 7: SVM (0.991)\n",
      "\n",
      "\n",
      "MODEL STABILITY RANKING - RECALL (based on average std across classes):\n",
      "  1. QDA: 0.0604\n",
      "  2. KNN: 0.0696\n",
      "  3. SVM: 0.0737\n",
      "  4. NN: 0.0779\n",
      "  5. RF: 0.0813\n",
      "  6. LR: 0.0902\n",
      "\n",
      "\n",
      "BALANCED PERFORMANCE ANALYSIS (Average of Recall and Specificity):\n",
      "\n",
      "Class ranking by balanced performance:\n",
      "  1. Class 7: 0.968\n",
      "  2. Class 5: 0.952\n",
      "  3. Class 1: 0.929\n",
      "  4. Class 4: 0.919\n",
      "  5. Class 6: 0.915\n",
      "  6. Class 3: 0.900\n",
      "  7. Class 2: 0.847\n",
      "\n",
      "\n",
      "MODEL STABILITY RANKING - SPECIFICITY (based on average std across classes):\n",
      "  1. QDA: 0.0126\n",
      "  2. SVM: 0.0128\n",
      "  3. KNN: 0.0129\n",
      "  4. RF: 0.0135\n",
      "  5. NN: 0.0145\n",
      "  6. LR: 0.0178\n",
      "\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Completed! Saved:\n",
      "- 24 numpy arrays (mean and std for each model and metric)\n",
      "- 4 CSV tables (recall and specificity, both with full and short model names)\n",
      "\n",
      "Files saved:\n",
      "- Numpy arrays: {model}_{metric}_mean.npy and {model}_{metric}_std.npy\n",
      "- CSV tables: recall_table.csv, specificity_table.csv (with short model names)\n",
      "- CSV tables: recall_table_full.csv, specificity_table_full.csv (with full model names)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Per-Class Recall and Specificity Analysis - Simplified Version\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_ROOT = 'output'\n",
    "METRICS_DIR = os.path.join(OUTPUT_ROOT, 'metrics')\n",
    "MODEL_SET = ['FS_PCA_NN', 'FS_PCA_SVM', 'RF', 'FS_PCA_QDA', 'FS_PCA_KNN', 'FS_PCA_LR']\n",
    "\n",
    "# Model display names\n",
    "MODEL_DISPLAY = {\n",
    "    'FS_PCA_NN': 'NN',\n",
    "    'FS_PCA_SVM': 'SVM',\n",
    "    'RF': 'RF',\n",
    "    'FS_PCA_QDA': 'QDA', \n",
    "    'FS_PCA_KNN': 'KNN',\n",
    "    'FS_PCA_LR': 'LR'\n",
    "}\n",
    "\n",
    "# Auto-detect number of folds\n",
    "def detect_n_folds():\n",
    "    if not os.path.exists(METRICS_DIR):\n",
    "        return 5\n",
    "    max_fold = 0\n",
    "    for model in MODEL_SET:\n",
    "        fold = 1\n",
    "        while os.path.exists(os.path.join(METRICS_DIR, f\"per_class_recall_{model}_{fold}.npy\")):\n",
    "            max_fold = max(max_fold, fold)\n",
    "            fold += 1\n",
    "    return max_fold if max_fold > 0 else 5\n",
    "\n",
    "N_FOLDS = detect_n_folds()\n",
    "\n",
    "def main():\n",
    "    print(f\"Analyzing recall and specificity across {N_FOLDS} folds\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Process recall\n",
    "    recall_results = {}\n",
    "    for model_name in MODEL_SET:\n",
    "        values = []\n",
    "        for fold_idx in range(1, N_FOLDS + 1):\n",
    "            filepath = os.path.join(METRICS_DIR, f\"per_class_recall_{model_name}_{fold_idx}.npy\")\n",
    "            if os.path.exists(filepath):\n",
    "                values.append(np.load(filepath))\n",
    "        \n",
    "        if values:\n",
    "            values = np.array(values)\n",
    "            mean_vals = np.mean(values, axis=0)\n",
    "            std_vals = np.std(values, axis=0)\n",
    "            \n",
    "            # Save arrays\n",
    "            np.save(f\"{model_name}_recall_mean.npy\", mean_vals)\n",
    "            np.save(f\"{model_name}_recall_std.npy\", std_vals)\n",
    "            \n",
    "            recall_results[model_name] = {'mean': mean_vals, 'std': std_vals}\n",
    "    \n",
    "    # Create recall table\n",
    "    recall_table_data = []\n",
    "    for class_idx in range(7):\n",
    "        row = [f\"Class {class_idx + 1}\"]\n",
    "        for model in MODEL_SET:\n",
    "            if model in recall_results:\n",
    "                m = recall_results[model]['mean'][class_idx]\n",
    "                s = recall_results[model]['std'][class_idx]\n",
    "                row.append(f\"{m:.3f} ± {s:.3f}\")\n",
    "            else:\n",
    "                row.append(\"N/A\")\n",
    "        recall_table_data.append(row)\n",
    "    \n",
    "    # 创建两个版本的DataFrame - 一个用于保存（完整模型名），一个用于显示（简短模型名）\n",
    "    recall_df = pd.DataFrame(recall_table_data, columns=['Class'] + MODEL_SET)\n",
    "    recall_df_display = pd.DataFrame(recall_table_data, columns=['Class'] + [MODEL_DISPLAY[m] for m in MODEL_SET])\n",
    "    \n",
    "    print(\"\\nRECALL (mean ± std)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(recall_df_display.to_string(index=False))\n",
    "    recall_df.to_csv('recall_table_full.csv', index=False)\n",
    "    recall_df_display.to_csv('recall_table.csv', index=False)\n",
    "    \n",
    "    # Process specificity\n",
    "    spec_results = {}\n",
    "    for model_name in MODEL_SET:\n",
    "        values = []\n",
    "        for fold_idx in range(1, N_FOLDS + 1):\n",
    "            filepath = os.path.join(METRICS_DIR, f\"per_class_specificity_{model_name}_{fold_idx}.npy\")\n",
    "            if os.path.exists(filepath):\n",
    "                values.append(np.load(filepath))\n",
    "        \n",
    "        if values:\n",
    "            values = np.array(values)\n",
    "            mean_vals = np.mean(values, axis=0)\n",
    "            std_vals = np.std(values, axis=0)\n",
    "            \n",
    "            # Save arrays\n",
    "            np.save(f\"{model_name}_specificity_mean.npy\", mean_vals)\n",
    "            np.save(f\"{model_name}_specificity_std.npy\", std_vals)\n",
    "            \n",
    "            spec_results[model_name] = {'mean': mean_vals, 'std': std_vals}\n",
    "    \n",
    "    # Create specificity table\n",
    "    spec_table_data = []\n",
    "    for class_idx in range(7):\n",
    "        row = [f\"Class {class_idx + 1}\"]\n",
    "        for model in MODEL_SET:\n",
    "            if model in spec_results:\n",
    "                m = spec_results[model]['mean'][class_idx]\n",
    "                s = spec_results[model]['std'][class_idx]\n",
    "                row.append(f\"{m:.3f} ± {s:.3f}\")\n",
    "            else:\n",
    "                row.append(\"N/A\")\n",
    "        spec_table_data.append(row)\n",
    "    \n",
    "    # 创建两个版本的DataFrame - 一个用于保存（完整模型名），一个用于显示（简短模型名）\n",
    "    spec_df = pd.DataFrame(spec_table_data, columns=['Class'] + MODEL_SET)\n",
    "    spec_df_display = pd.DataFrame(spec_table_data, columns=['Class'] + [MODEL_DISPLAY[m] for m in MODEL_SET])\n",
    "    \n",
    "    print(\"\\n\\nSPECIFICITY (mean ± std)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(spec_df_display.to_string(index=False))\n",
    "    spec_df.to_csv('specificity_table_full.csv', index=False)\n",
    "    spec_df_display.to_csv('specificity_table.csv', index=False)\n",
    "    \n",
    "    # Class difficulty analysis for RECALL\n",
    "    print(\"\\n\\nCLASS DIFFICULTY RANKING - RECALL (based on average recall across all models):\")\n",
    "    class_difficulties_recall = []\n",
    "    \n",
    "    for class_idx in range(7):\n",
    "        class_recalls = []\n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in recall_results:\n",
    "                class_recalls.append(recall_results[model_name]['mean'][class_idx])\n",
    "        avg_recall = np.mean(class_recalls) if class_recalls else 0\n",
    "        class_difficulties_recall.append((f\"Class {class_idx + 1}\", avg_recall))\n",
    "    \n",
    "    class_difficulties_recall.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for rank, (class_name, avg_recall) in enumerate(class_difficulties_recall, 1):\n",
    "        print(f\"  {rank}. {class_name}: {avg_recall:.3f}\")\n",
    "    \n",
    "    # Class difficulty analysis for SPECIFICITY\n",
    "    print(\"\\n\\nCLASS DIFFICULTY RANKING - SPECIFICITY (based on average specificity across all models):\")\n",
    "    class_difficulties_spec = []\n",
    "    \n",
    "    for class_idx in range(7):\n",
    "        class_specs = []\n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in spec_results:\n",
    "                class_specs.append(spec_results[model_name]['mean'][class_idx])\n",
    "        avg_spec = np.mean(class_specs) if class_specs else 0\n",
    "        class_difficulties_spec.append((f\"Class {class_idx + 1}\", avg_spec))\n",
    "    \n",
    "    class_difficulties_spec.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for rank, (class_name, avg_spec) in enumerate(class_difficulties_spec, 1):\n",
    "        print(f\"  {rank}. {class_name}: {avg_spec:.3f}\")\n",
    "    \n",
    "    # Best model for each class - RECALL\n",
    "    print(\"\\n\\nBEST MODEL FOR EACH CLASS - RECALL:\")\n",
    "    for class_idx in range(7):\n",
    "        best_recall = -1\n",
    "        best_model = \"\"\n",
    "        \n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in recall_results:\n",
    "                recall_val = recall_results[model_name]['mean'][class_idx]\n",
    "                if recall_val > best_recall:\n",
    "                    best_recall = recall_val\n",
    "                    best_model = MODEL_DISPLAY.get(model_name, model_name)\n",
    "        \n",
    "        print(f\"  Class {class_idx + 1}: {best_model} ({best_recall:.3f})\")\n",
    "    \n",
    "    # Best model for each class - SPECIFICITY\n",
    "    print(\"\\n\\nBEST MODEL FOR EACH CLASS - SPECIFICITY:\")\n",
    "    for class_idx in range(7):\n",
    "        best_spec = -1\n",
    "        best_model = \"\"\n",
    "        \n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in spec_results:\n",
    "                spec_val = spec_results[model_name]['mean'][class_idx]\n",
    "                if spec_val > best_spec:\n",
    "                    best_spec = spec_val\n",
    "                    best_model = MODEL_DISPLAY.get(model_name, model_name)\n",
    "        \n",
    "        print(f\"  Class {class_idx + 1}: {best_model} ({best_spec:.3f})\")\n",
    "    \n",
    "    # Model stability ranking\n",
    "    print(\"\\n\\nMODEL STABILITY RANKING - RECALL (based on average std across classes):\")\n",
    "    stability_recall = []\n",
    "    \n",
    "    for model_name in MODEL_SET:\n",
    "        if model_name in recall_results:\n",
    "            avg_std = np.mean(recall_results[model_name]['std'])\n",
    "            stability_recall.append((MODEL_DISPLAY.get(model_name, model_name), avg_std))\n",
    "    \n",
    "    stability_recall.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for rank, (model, avg_std) in enumerate(stability_recall, 1):\n",
    "        print(f\"  {rank}. {model}: {avg_std:.4f}\")\n",
    "    \n",
    "    # Balanced performance analysis\n",
    "    print(\"\\n\\nBALANCED PERFORMANCE ANALYSIS (Average of Recall and Specificity):\")\n",
    "    balanced_scores = []\n",
    "    \n",
    "    for class_idx in range(7):\n",
    "        class_balanced = []\n",
    "        for model_name in MODEL_SET:\n",
    "            if model_name in recall_results and model_name in spec_results:\n",
    "                balanced = (recall_results[model_name]['mean'][class_idx] + \n",
    "                           spec_results[model_name]['mean'][class_idx]) / 2\n",
    "                class_balanced.append(balanced)\n",
    "        avg_balanced = np.mean(class_balanced) if class_balanced else 0\n",
    "        balanced_scores.append((f\"Class {class_idx + 1}\", avg_balanced))\n",
    "    \n",
    "    balanced_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nClass ranking by balanced performance:\")\n",
    "    for rank, (class_name, score) in enumerate(balanced_scores, 1):\n",
    "        print(f\"  {rank}. {class_name}: {score:.3f}\")\n",
    "    \n",
    "    print(\"\\n\\nMODEL STABILITY RANKING - SPECIFICITY (based on average std across classes):\")\n",
    "    stability_spec = []\n",
    "    \n",
    "    for model_name in MODEL_SET:\n",
    "        if model_name in spec_results:\n",
    "            avg_std = np.mean(spec_results[model_name]['std'])\n",
    "            stability_spec.append((MODEL_DISPLAY.get(model_name, model_name), avg_std))\n",
    "    \n",
    "    stability_spec.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for rank, (model, avg_std) in enumerate(stability_spec, 1):\n",
    "        print(f\"  {rank}. {model}: {avg_std:.4f}\")\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\" * 70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Completed! Saved:\")\n",
    "    print(f\"- {2 * len(MODEL_SET) * 2} numpy arrays (mean and std for each model and metric)\")\n",
    "    print(f\"- 4 CSV tables (recall and specificity, both with full and short model names)\")\n",
    "    print(\"\\nFiles saved:\")\n",
    "    print(\"- Numpy arrays: {model}_{metric}_mean.npy and {model}_{metric}_std.npy\")\n",
    "    print(\"- CSV tables: recall_table.csv, specificity_table.csv (with short model names)\")\n",
    "    print(\"- CSV tables: recall_table_full.csv, specificity_table_full.csv (with full model names)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
