{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class Accuracy Analysis\n",
      "==================================================\n",
      "\n",
      "Loading per-class accuracies from output folder...\n",
      "\n",
      "Calculating mean and standard deviation across folds...\n",
      "Saved statistics for FS_PCA_NN\n",
      "Saved statistics for FS_PCA_SVM\n",
      "Saved statistics for RF\n",
      "Saved statistics for FS_PCA_QDA\n",
      "Saved statistics for FS_PCA_KNN\n",
      "Saved statistics for FS_PCA_LR\n",
      "\n",
      "Creating formatted table...\n",
      "\n",
      "================================================================================\n",
      "PER-CLASS ACCURACY TABLE (mean ± std across 5 folds)\n",
      "================================================================================\n",
      "  Class            NN           SVM            RF           QDA           KNN            LR\n",
      "Class 1 0.859 ± 0.029 0.941 ± 0.053 0.894 ± 0.101 0.918 ± 0.060 0.941 ± 0.053 0.847 ± 0.080\n",
      "Class 2 0.812 ± 0.044 0.812 ± 0.069 0.812 ± 0.058 0.718 ± 0.044 0.788 ± 0.088 0.765 ± 0.064\n",
      "Class 3 0.824 ± 0.105 0.882 ± 0.098 0.859 ± 0.109 0.894 ± 0.108 0.788 ± 0.096 0.824 ± 0.112\n",
      "Class 4 0.859 ± 0.029 0.929 ± 0.044 0.918 ± 0.071 0.800 ± 0.080 0.918 ± 0.029 0.882 ± 0.037\n",
      "Class 5 0.953 ± 0.044 0.965 ± 0.047 0.953 ± 0.024 0.976 ± 0.029 0.965 ± 0.029 0.941 ± 0.037\n",
      "Class 6 0.847 ± 0.103 0.824 ± 0.098 0.788 ± 0.060 0.918 ± 0.047 0.800 ± 0.103 0.776 ± 0.136\n",
      "Class 7 0.965 ± 0.071 0.953 ± 0.069 0.953 ± 0.058 0.988 ± 0.024 0.976 ± 0.029 0.941 ± 0.091\n",
      "\n",
      "Table saved to per_class_accuracy_table.csv\n",
      "\n",
      "LaTeX table saved to per_class_accuracy_table.tex\n",
      "\n",
      "================================================================================\n",
      "DETAILED PER-CLASS ACCURACY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "FS_PCA_NN:\n",
      "----------------------------------------\n",
      "  Class 1: 0.8588 ± 0.0288\n",
      "  Class 2: 0.8118 ± 0.0440\n",
      "  Class 3: 0.8235 ± 0.1052\n",
      "  Class 4: 0.8588 ± 0.0288\n",
      "  Class 5: 0.9529 ± 0.0440\n",
      "  Class 6: 0.8471 ± 0.1026\n",
      "  Class 7: 0.9647 ± 0.0706\n",
      "  Overall mean: 0.8739\n",
      "  Overall std: 0.0606\n",
      "\n",
      "FS_PCA_SVM:\n",
      "----------------------------------------\n",
      "  Class 1: 0.9412 ± 0.0526\n",
      "  Class 2: 0.8118 ± 0.0686\n",
      "  Class 3: 0.8824 ± 0.0984\n",
      "  Class 4: 0.9294 ± 0.0440\n",
      "  Class 5: 0.9647 ± 0.0471\n",
      "  Class 6: 0.8235 ± 0.0984\n",
      "  Class 7: 0.9529 ± 0.0686\n",
      "  Overall mean: 0.9008\n",
      "  Overall std: 0.0683\n",
      "\n",
      "RF:\n",
      "----------------------------------------\n",
      "  Class 1: 0.8941 ± 0.1012\n",
      "  Class 2: 0.8118 ± 0.0576\n",
      "  Class 3: 0.8588 ± 0.1091\n",
      "  Class 4: 0.9176 ± 0.0706\n",
      "  Class 5: 0.9529 ± 0.0235\n",
      "  Class 6: 0.7882 ± 0.0600\n",
      "  Class 7: 0.9529 ± 0.0576\n",
      "  Overall mean: 0.8824\n",
      "  Overall std: 0.0685\n",
      "\n",
      "FS_PCA_QDA:\n",
      "----------------------------------------\n",
      "  Class 1: 0.9176 ± 0.0600\n",
      "  Class 2: 0.7176 ± 0.0440\n",
      "  Class 3: 0.8941 ± 0.1078\n",
      "  Class 4: 0.8000 ± 0.0798\n",
      "  Class 5: 0.9765 ± 0.0288\n",
      "  Class 6: 0.9176 ± 0.0471\n",
      "  Class 7: 0.9882 ± 0.0235\n",
      "  Overall mean: 0.8874\n",
      "  Overall std: 0.0559\n",
      "\n",
      "FS_PCA_KNN:\n",
      "----------------------------------------\n",
      "  Class 1: 0.9412 ± 0.0526\n",
      "  Class 2: 0.7882 ± 0.0880\n",
      "  Class 3: 0.7882 ± 0.0956\n",
      "  Class 4: 0.9176 ± 0.0288\n",
      "  Class 5: 0.9647 ± 0.0288\n",
      "  Class 6: 0.8000 ± 0.1026\n",
      "  Class 7: 0.9765 ± 0.0288\n",
      "  Overall mean: 0.8824\n",
      "  Overall std: 0.0607\n",
      "\n",
      "FS_PCA_LR:\n",
      "----------------------------------------\n",
      "  Class 1: 0.8471 ± 0.0798\n",
      "  Class 2: 0.7647 ± 0.0644\n",
      "  Class 3: 0.8235 ± 0.1116\n",
      "  Class 4: 0.8824 ± 0.0372\n",
      "  Class 5: 0.9412 ± 0.0372\n",
      "  Class 6: 0.7765 ± 0.1362\n",
      "  Class 7: 0.9412 ± 0.0911\n",
      "  Overall mean: 0.8538\n",
      "  Overall std: 0.0797\n",
      "\n",
      "================================================================================\n",
      "SUMMARY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Best model for each class (based on mean accuracy):\n",
      "  Class 1: SVM (0.941)\n",
      "  Class 2: NN (0.812)\n",
      "  Class 3: QDA (0.894)\n",
      "  Class 4: SVM (0.929)\n",
      "  Class 5: QDA (0.976)\n",
      "  Class 6: QDA (0.918)\n",
      "  Class 7: QDA (0.988)\n",
      "\n",
      "Model stability ranking (based on average std across classes):\n",
      "  1. QDA: 0.0559\n",
      "  2. NN: 0.0606\n",
      "  3. KNN: 0.0607\n",
      "  4. SVM: 0.0683\n",
      "  5. RF: 0.0685\n",
      "  6. LR: 0.0797\n",
      "\n",
      "Class difficulty ranking (based on average accuracy across all models):\n",
      "  1. Class 7: 0.963\n",
      "  2. Class 5: 0.959\n",
      "  3. Class 1: 0.900\n",
      "  4. Class 4: 0.884\n",
      "  5. Class 3: 0.845\n",
      "  6. Class 6: 0.825\n",
      "  7. Class 2: 0.784\n",
      "\n",
      "================================================================================\n",
      "Analysis complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Per-Class Accuracy Analysis Script\n",
    "Analyzes the per-class accuracy for each model across all test folds\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_ROOT = 'output'\n",
    "METRICS_DIR = os.path.join(OUTPUT_ROOT, 'metrics')\n",
    "N_FOLDS = 5  # Number of CV folds\n",
    "N_CLASSES = 7  # Number of classes\n",
    "MODEL_SET = ['FS_PCA_NN', 'FS_PCA_SVM', 'RF', 'FS_PCA_QDA', 'FS_PCA_KNN', 'FS_PCA_LR']\n",
    "\n",
    "# Model display names for better formatting\n",
    "MODEL_DISPLAY_NAMES = {\n",
    "    'FS_PCA_NN': 'NN',\n",
    "    'FS_PCA_SVM': 'SVM', \n",
    "    'RF': 'RF',\n",
    "    'FS_PCA_QDA': 'QDA',\n",
    "    'FS_PCA_KNN': 'KNN',\n",
    "    'FS_PCA_LR': 'LR'\n",
    "}\n",
    "\n",
    "def load_per_class_accuracies():\n",
    "    \"\"\"\n",
    "    Load per-class accuracies (recall) for all models and folds\n",
    "    Note: Per-class recall = per-class accuracy (TP / (TP + FN))\n",
    "    \"\"\"\n",
    "    all_accuracies = {}\n",
    "    \n",
    "    for model_name in MODEL_SET:\n",
    "        model_accuracies = []\n",
    "        \n",
    "        for fold_idx in range(1, N_FOLDS + 1):\n",
    "            # Load per-class recall which is equivalent to per-class accuracy\n",
    "            filename = f\"per_class_recall_{model_name}_{fold_idx}.npy\"\n",
    "            filepath = os.path.join(METRICS_DIR, filename)\n",
    "            \n",
    "            if os.path.exists(filepath):\n",
    "                per_class_acc = np.load(filepath)\n",
    "                model_accuracies.append(per_class_acc)\n",
    "            else:\n",
    "                print(f\"Warning: File not found - {filename}\")\n",
    "        \n",
    "        if model_accuracies:\n",
    "            # Stack all folds: shape (n_folds, n_classes)\n",
    "            all_accuracies[model_name] = np.array(model_accuracies)\n",
    "        else:\n",
    "            print(f\"Error: No data found for model {model_name}\")\n",
    "    \n",
    "    return all_accuracies\n",
    "\n",
    "def calculate_statistics(all_accuracies):\n",
    "    \"\"\"\n",
    "    Calculate mean and std for each model across all folds\n",
    "    \"\"\"\n",
    "    statistics = {}\n",
    "    \n",
    "    for model_name, accuracies in all_accuracies.items():\n",
    "        # accuracies shape: (n_folds, n_classes)\n",
    "        mean_acc = np.mean(accuracies, axis=0)  # Shape: (n_classes,)\n",
    "        std_acc = np.std(accuracies, axis=0)    # Shape: (n_classes,)\n",
    "        \n",
    "        statistics[model_name] = {\n",
    "            'mean': mean_acc,\n",
    "            'std': std_acc\n",
    "        }\n",
    "        \n",
    "        # Save as numpy arrays\n",
    "        np.save(f\"{model_name}_per_class_acc_mean.npy\", mean_acc)\n",
    "        np.save(f\"{model_name}_per_class_acc_std.npy\", std_acc)\n",
    "        print(f\"Saved statistics for {model_name}\")\n",
    "    \n",
    "    return statistics\n",
    "\n",
    "def create_formatted_table(statistics):\n",
    "    \"\"\"\n",
    "    Create a formatted table showing mean ± std for each class and model\n",
    "    \"\"\"\n",
    "    # Create empty dataframe\n",
    "    table_data = []\n",
    "    \n",
    "    # For each class (row)\n",
    "    for class_idx in range(N_CLASSES):\n",
    "        row_data = {'Class': f'Class {class_idx + 1}'}\n",
    "        \n",
    "        # For each model (column)\n",
    "        for model_name in MODEL_SET:\n",
    "            mean_val = statistics[model_name]['mean'][class_idx]\n",
    "            std_val = statistics[model_name]['std'][class_idx]\n",
    "            \n",
    "            # Format as \"mean ± std\" with 3 decimal places\n",
    "            formatted_value = f\"{mean_val:.3f} ± {std_val:.3f}\"\n",
    "            \n",
    "            # Use display name for column\n",
    "            display_name = MODEL_DISPLAY_NAMES[model_name]\n",
    "            row_data[display_name] = formatted_value\n",
    "        \n",
    "        table_data.append(row_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(table_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def print_detailed_statistics(statistics):\n",
    "    \"\"\"\n",
    "    Print detailed statistics for verification\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED PER-CLASS ACCURACY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for model_name in MODEL_SET:\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        mean_acc = statistics[model_name]['mean']\n",
    "        std_acc = statistics[model_name]['std']\n",
    "        \n",
    "        for class_idx in range(N_CLASSES):\n",
    "            print(f\"  Class {class_idx + 1}: {mean_acc[class_idx]:.4f} ± {std_acc[class_idx]:.4f}\")\n",
    "        \n",
    "        # Overall statistics\n",
    "        print(f\"  Overall mean: {np.mean(mean_acc):.4f}\")\n",
    "        print(f\"  Overall std: {np.mean(std_acc):.4f}\")\n",
    "\n",
    "def save_latex_table(df, filename='per_class_accuracy_table.tex'):\n",
    "    \"\"\"\n",
    "    Save the table in LaTeX format\n",
    "    \"\"\"\n",
    "    latex_table = df.to_latex(index=False, escape=False)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(latex_table)\n",
    "    print(f\"\\nLaTeX table saved to {filename}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main analysis function\n",
    "    \"\"\"\n",
    "    print(\"Per-Class Accuracy Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load per-class accuracies\n",
    "    print(\"\\nLoading per-class accuracies from output folder...\")\n",
    "    all_accuracies = load_per_class_accuracies()\n",
    "    \n",
    "    if not all_accuracies:\n",
    "        print(\"Error: No data loaded. Please check the output folder.\")\n",
    "        return\n",
    "    \n",
    "    # Calculate statistics\n",
    "    print(\"\\nCalculating mean and standard deviation across folds...\")\n",
    "    statistics = calculate_statistics(all_accuracies)\n",
    "    \n",
    "    # Create formatted table\n",
    "    print(\"\\nCreating formatted table...\")\n",
    "    table_df = create_formatted_table(statistics)\n",
    "    \n",
    "    # Display table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PER-CLASS ACCURACY TABLE (mean ± std across {} folds)\".format(N_FOLDS))\n",
    "    print(\"=\"*80)\n",
    "    print(table_df.to_string(index=False))\n",
    "    \n",
    "    # Save table to CSV\n",
    "    csv_filename = 'per_class_accuracy_table.csv'\n",
    "    table_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"\\nTable saved to {csv_filename}\")\n",
    "    \n",
    "    # Save LaTeX version\n",
    "    save_latex_table(table_df)\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print_detailed_statistics(statistics)\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Find best model for each class\n",
    "    print(\"\\nBest model for each class (based on mean accuracy):\")\n",
    "    for class_idx in range(N_CLASSES):\n",
    "        best_acc = -1\n",
    "        best_model = \"\"\n",
    "        \n",
    "        for model_name in MODEL_SET:\n",
    "            mean_acc = statistics[model_name]['mean'][class_idx]\n",
    "            if mean_acc > best_acc:\n",
    "                best_acc = mean_acc\n",
    "                best_model = MODEL_DISPLAY_NAMES[model_name]\n",
    "        \n",
    "        print(f\"  Class {class_idx + 1}: {best_model} ({best_acc:.3f})\")\n",
    "    \n",
    "    # Find most stable model (lowest average std)\n",
    "    print(\"\\nModel stability ranking (based on average std across classes):\")\n",
    "    stability_scores = []\n",
    "    \n",
    "    for model_name in MODEL_SET:\n",
    "        avg_std = np.mean(statistics[model_name]['std'])\n",
    "        stability_scores.append((MODEL_DISPLAY_NAMES[model_name], avg_std))\n",
    "    \n",
    "    stability_scores.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for rank, (model, avg_std) in enumerate(stability_scores, 1):\n",
    "        print(f\"  {rank}. {model}: {avg_std:.4f}\")\n",
    "    \n",
    "    # Class difficulty analysis\n",
    "    print(\"\\nClass difficulty ranking (based on average accuracy across all models):\")\n",
    "    class_difficulties = []\n",
    "    \n",
    "    for class_idx in range(N_CLASSES):\n",
    "        class_accs = []\n",
    "        for model_name in MODEL_SET:\n",
    "            class_accs.append(statistics[model_name]['mean'][class_idx])\n",
    "        avg_acc = np.mean(class_accs)\n",
    "        class_difficulties.append((f\"Class {class_idx + 1}\", avg_acc))\n",
    "    \n",
    "    class_difficulties.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for rank, (class_name, avg_acc) in enumerate(class_difficulties, 1):\n",
    "        print(f\"  {rank}. {class_name}: {avg_acc:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Analysis complete!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
